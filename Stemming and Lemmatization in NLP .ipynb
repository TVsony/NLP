{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6251817",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization in NLP \n",
    "\n",
    "Stemming and lemmatization are techniques used in natural language processing (NLP) to reduce words to their base\n",
    "or root forms, which helps in normalizing and standardizing text data. While both techniques aim to achieve similar goals,\n",
    "they operate differently and have distinct characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552fc1e0",
   "metadata": {},
   "source": [
    "### Stemming:\n",
    "Stemming is the process of removing affixes from words to derive their stems, which are the base or root forms.\n",
    "Stemming algorithms apply heuristic rules to chop off prefixes or suffixes from words, resulting in the stem. \n",
    "The goal of stemming is to map different inflected or derived forms of a word to the same root form, \n",
    "thereby reducing variation and improving information retrieval or text analysis tasks.\n",
    "\n",
    "For example, the word \"running\" would be stemmed to \"run,\" \"cats\" would be stemmed to \"cat,\" and \"better\" \n",
    "would be stemmed to \"better.\" Stemming is typically a rule-based process and may not always produce valid words as stems,\n",
    "but it is computationally efficient and straightforward to implement.\n",
    "\n",
    "One of the most commonly used stemming algorithms is the Porter Stemmer, developed by Martin Porter. \n",
    "NLTK provides an implementation of the Porter Stemmer, along with other stemming algorithms like the \n",
    "Lancaster Stemmer and Snowball Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42012591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer: ['run', 'cat', 'better', 'run']\n",
      "Lancaster Stemmer: ['run', 'cat', 'bet', 'run']\n",
      "Snowball Stemmer: ['run', 'cat', 'better', 'run']\n"
     ]
    }
   ],
   "source": [
    "# their are few types of stemmers available in NLTK package .We will talk about popular below two\n",
    "# 1 Porter stemmer\n",
    "# 2 Lancaster stemmer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "# Sample words\n",
    "words = ['running', 'cats', 'better', 'running']\n",
    "\n",
    "# Initialize stemmers\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")  # You need to specify the language for SnowballStemmer\n",
    "\n",
    "# Stem words using each stemmer\n",
    "porter_stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
    "lancaster_stemmed_words = [lancaster_stemmer.stem(word) for word in words]\n",
    "snowball_stemmed_words = [snowball_stemmer.stem(word) for word in words]\n",
    "\n",
    "# Print stemmed words\n",
    "print(\"Porter Stemmer:\", porter_stemmed_words)\n",
    "print(\"Lancaster Stemmer:\", lancaster_stemmed_words)\n",
    "print(\"Snowball Stemmer:\", snowball_stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4a898",
   "metadata": {},
   "source": [
    "### Poter Stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac59ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed word: hobbi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Stem the word \"hobby\"\n",
    "stemmed_word = porter_stemmer.stem(\"hobby\")\n",
    "\n",
    "# Print the stemmed word\n",
    "print(\"Stemmed word:\", stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9433d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed word: hobbi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Stem the word \"hobbies\"\n",
    "stemmed_word = porter_stemmer.stem(\"hobbies\")\n",
    "\n",
    "# Print the stemmed word\n",
    "print(\"Stemmed word:\", stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4110015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed word: comput\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Stem the word \"computer\"\n",
    "stemmed_word = porter_stemmer.stem(\"computer\")\n",
    "\n",
    "# Print the stemmed word\n",
    "print(\"Stemmed word:\", stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786a24d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed word: comput\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Stem the word \"computation\"\n",
    "stemmed_word = porter_stemmer.stem(\"computation\")\n",
    "\n",
    "# Print the stemmed word\n",
    "print(\"Stemmed word:\", stemmed_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834adc3",
   "metadata": {},
   "source": [
    "### Lancaster stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c3aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed word: hobby\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Initialize LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "# Stem the word \"hobby\"\n",
    "stemmed_word = lancaster_stemmer.stem(\"hobby\")\n",
    "\n",
    "# Print the stemmed word\n",
    "print(\"Stemmed word:\", stemmed_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77100be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed word: hobby\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Initialize LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "# Stem the word \"hobbies\"\n",
    "stemmed_word = lancaster_stemmer.stem(\"hobbies\")\n",
    "\n",
    "# Print the stemmed word\n",
    "print(\"Stemmed word:\", stemmed_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e8c502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed word: comput\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Initialize LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "# Stem the word \"computer\"\n",
    "stemmed_word = lancaster_stemmer.stem(\"computer\")\n",
    "\n",
    "# Print the stemmed word\n",
    "print(\"Stemmed word:\", stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a4874a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed word: comput\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Initialize LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "# Stem the word \"computation\"\n",
    "stemmed_word = lancaster_stemmer.stem(\"computation\")\n",
    "\n",
    "# Print the stemmed word\n",
    "print(\"Stemmed word:\", stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f92b66ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'was',\n",
       " 'going',\n",
       " 'to',\n",
       " 'the',\n",
       " 'office',\n",
       " 'on',\n",
       " 'my',\n",
       " 'time',\n",
       " 'bike',\n",
       " 'when',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'car',\n",
       " 'passing',\n",
       " 'by',\n",
       " 'hit',\n",
       " 'the',\n",
       " 'tree',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I was going to the office on my time bike when i saw car passing by hit the tree.\"\n",
    "token = list(nltk.word_tokenize (sentence))\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0b885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was going to the office on my time bike when i saw car passing by hit the tree.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3abc1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowball Stemmer: i   w a s   g o i n g   t o   t h e   o f f i c e   o n   m y   t i m e   b i k e   w h e n   i   s a w   c a r   p a s s i n g   b y   h i t   t h e   t r e e .\n",
      "Lancaster Stemmer: i   w a s   g o i n g   t o   t h e   o f f i c e   o n   m y   t i m e   b i k e   w h e n   i   s a w   c a r   p a s s i n g   b y   h i t   t h e   t r e e .\n",
      "Porter Stemmer: i   w a s   g o i n g   t o   t h e   o f f i c e   o n   m y   t i m e   b i k e   w h e n   i   s a w   c a r   p a s s i n g   b y   h i t   t h e   t r e e .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer, LancasterStemmer, PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Sample tokens\n",
    "tokens = \"I was going to the office on my time bike when i saw car passing by hit the tree.\"\n",
    "\n",
    "# Initialize stemmers\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Stem tokens using each stemmer\n",
    "snowball_stemmed = [snowball_stemmer.stem(token) for token in tokens]\n",
    "lancaster_stemmed = [lancaster_stemmer.stem(token) for token in tokens]\n",
    "porter_stemmed = [porter_stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# Print stemmed tokens\n",
    "print(\"Snowball Stemmer:\", ' '.join(snowball_stemmed))\n",
    "print(\"Lancaster Stemmer:\", ' '.join(lancaster_stemmed))\n",
    "print(\"Porter Stemmer:\", ' '.join(porter_stemmed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7840666",
   "metadata": {},
   "source": [
    "# Lemmatization:\n",
    "Lemmatization, on the other hand, involves determining the lemma or canonical form of a word based on its intended \n",
    "meaning in the language. Unlike stemming, which simply chops off affixes, lemmatization considers the context \n",
    "and semantics of words to derive their base forms. Lemmatization requires access to a dictionary or lexicon that maps words\n",
    "to their lemmas, allowing it to produce valid words as output.\n",
    "\n",
    "For example, the word \"better\" would be lemmatized to \"good,\" \"running\" would be lemmatized to \"run,\" and \"cats\"\n",
    "would be lemmatized to \"cat.\" Lemmatization ensures that the resulting base forms are valid words, making it suitable \n",
    "for applications where word sense disambiguation and linguistic accuracy are crucial.\n",
    "\n",
    "NLTK provides lemmatization functionality through the WordNet Lemmatizer, which is based on WordNet, \n",
    "a lexical database of English.\n",
    "The WordNet Lemmatizer maps words to their lemmas using WordNet's hierarchical structure of synsets\n",
    "(sets of synonymous words or phrases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d9802c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb3917c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('running'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6af7088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('runs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db691d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('run'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2b18e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('running',pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8104362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('runs',pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7579fafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('run',pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23984b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming forBring is bring\n",
      "Stemming forKing is king\n",
      "Stemming forGoing is go\n",
      "Stemming forAnything is anyth\n",
      "Stemming forSing is sing\n",
      "Stemming forRing is ring\n",
      "Stemming forNothing is noth\n",
      "Stemming forThing is thing\n",
      "Stemming for. is .\n"
     ]
    }
   ],
   "source": [
    "# stemming \n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "text = \"Bring King Going Anything Sing Ring Nothing Thing.\"\n",
    "porter_stemmer = PorterStemmer()\n",
    "tokenization =nltk.word_tokenize(text)\n",
    "\n",
    "for w in tokenization:\n",
    "    print(\"Stemming for{} is {}\".format(w,porter_stemmer.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c16d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma for Bring is Bring\n",
      "Lemma for King is King\n",
      "Lemma for Going is Going\n",
      "Lemma for Anything is Anything\n",
      "Lemma for Sing is Sing\n",
      "Lemma for Ring is Ring\n",
      "Lemma for Nothing is Nothing\n",
      "Lemma for Thing is Thing\n",
      "Lemma for . is .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Sample text\n",
    "text = \"Bring King Going Anything Sing Ring Nothing Thing.\"\n",
    "\n",
    "# Initialize WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "\n",
    "# Lemmatize each word and print the result\n",
    "for w in tokenization:\n",
    "    print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95e4e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma for The is The\n",
      "Lemma for quick is quick\n",
      "Lemma for brown is brown\n",
      "Lemma for foxes is fox\n",
      "Lemma for are is are\n",
      "Lemma for jumping is jumping\n",
      "Lemma for over is over\n",
      "Lemma for the is the\n",
      "Lemma for lazy is lazy\n",
      "Lemma for dogs is dog\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Sample text\n",
    "text = \"The quick brown foxes are jumping over the lazy dogs\"\n",
    "\n",
    "# Initialize WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "\n",
    "# Lemmatize each word and print the result\n",
    "for w in tokenization:\n",
    "    print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43054bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized words:\n",
      "The -> The\n",
      "quick -> quick\n",
      "brown -> brown\n",
      "foxes -> fox\n",
      "are -> are\n",
      "jumping -> jumping\n",
      "over -> over\n",
      "the -> the\n",
      "lazy -> lazy\n",
      "dogs -> dog\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Sample text\n",
    "text = \"The quick brown foxes are jumping over the lazy dogs\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "# Initialize WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize each word in the text\n",
    "lemmatized_words = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Print the lemmatized words\n",
    "print(\"Lemmatized words:\")\n",
    "for word, lemma in zip(words, lemmatized_words):\n",
    "    print(\"{} -> {}\".format(word, lemma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d46e98ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized words:\n",
      "The -> The\n",
      "wolves -> wolf\n",
      "were -> were\n",
      "running -> running\n",
      "through -> through\n",
      "the -> the\n",
      "forests -> forest\n",
      "and -> and\n",
      "barking -> barking\n",
      "loudly -> loudly\n",
      "at -> at\n",
      "the -> the\n",
      "moon -> moon\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Sample text\n",
    "text = \"The wolves were running through the forests and barking loudly at the moon.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "# Initialize WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize each word in the text\n",
    "lemmatized_words = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Print the lemmatized words\n",
    "print(\"Lemmatized words:\")\n",
    "for word, lemma in zip(words, lemmatized_words):\n",
    "    print(\"{} -> {}\".format(word, lemma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c08111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
