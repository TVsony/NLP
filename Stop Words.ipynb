{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c813fc",
   "metadata": {},
   "source": [
    "# Stop Words \n",
    "Stop words are common words that are often filtered out from text data during natural language processing (NLP) tasks.\n",
    "Examples of stop words in English include \"the,\" \"is,\" \"and,\" \"in,\" \"of,\" etc.\n",
    "Stop words is to reduce the dimensionality of text data and to focus on the words that carry more meaningful information\n",
    "for a particular NLP task, such as sentiment analysis, document classification, or information retrieval.\n",
    "By filtering out stop words, we can often improve the efficiency and accuracy of text processing algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a68d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bhimr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How you can access and use stop words in NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7cc28b",
   "metadata": {},
   "source": [
    "# NLTK (Natural Language Toolkit)\n",
    "NLTK (Natural Language Toolkit) is a popular Python library for working with human language data.\n",
    "It provides various tools and resources for tasks such as tokenization, stemming, lemmatization, part-of-speech tagging,\n",
    "and more. NLTK also includes a list of common stop words for different languages, \n",
    "which can be useful for text preprocessing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f79aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get English stop words\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "stop_words = (stopwords.words('english'))\n",
    "# Print the list of English stop words\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398240e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5767c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mightn', 'nor', \"couldn't\", 'couldn', 're', \"hasn't\", 'very', 'some', 'ours', 'isn', 'o', 'hadn', 'own', \"needn't\", \"haven't\", \"aren't\", 'now', 'their', 'the', \"should've\", 'so', 'it', 'our', 'more', 'him', \"she's\", 'doesn', 'herself', 'me', 'are', 'few', 'most', 'themselves', 'does', 'to', 'not', 'through', \"didn't\", 'they', \"shouldn't\", \"you'd\", 'hers', 'can', 'after', 'an', 'just', \"it's\", \"won't\", 'be', 'should', 'until', 'were', 'by', 'don', 'again', 'than', 'hasn', \"wasn't\", 'or', 'her', 'as', 'too', \"you'll\", 'in', 'mustn', 'what', 'how', 'd', 'he', 'into', \"mightn't\", 'before', 'you', 'other', 'weren', 'where', 'm', 'on', 'she', 'yourselves', 'theirs', 'off', 'i', \"wouldn't\", 'his', 'will', 'above', 'at', 'once', 'my', 'both', 'aren', 'such', 'was', 'll', 'a', \"weren't\", 'words', \"shan't\", 'do', 'is', 'under', 'y', 'yours', 'been', 'am', 'needn', 'if', 'your', 'down', 'these', 'up', 'here', 'that', 'about', 'who', 'between', 'this', 'its', 'for', 'why', 'custom', \"you've\", 'himself', 'those', 'shan', 'any', 'ma', 's', 'wasn', 'because', 'wouldn', 'which', 'over', \"mustn't\", \"hadn't\", 'did', 'below', 't', 'ain', 'added', 'against', 'won', 'stop', 'only', 'of', 'and', 'them', 'being', 'from', 'all', 'no', 'while', 'didn', 'doing', \"you're\", 'ourselves', 'having', \"doesn't\", 'each', 'whom', 'had', \"that'll\", 'when', 'itself', 'haven', 'then', 'yourself', \"don't\", 'shouldn', 'but', 'further', 'myself', 'out', 'with', 'during', 'we', 've', 'has', 'there', 'same', 'have', \"isn't\"}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Add custom stopwords\n",
    "custom_stopwords = ['custom', 'stop', 'words', 'added']\n",
    "\n",
    "# Update the stop words set\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "# Print the updated list of stop words\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47a6036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e525940d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore Punctuations in our sentences \n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e7873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords and punctuations from the above set as texts.\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "punct = string.punctuation\n",
    "stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a97957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d6711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 118\n",
      "Length of cleaned text: 11\n",
      "\n",
      "Cleaned text: ['India', 'Hindi', 'Bharat', 'officially', 'republic', 'India', 'country', 'south', 'Asia', 'seventh-largest', 'country']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhimr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bhimr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define the text\n",
    "text = \"India (Hindi:Bharat), officially the republic of India, is a country in south Asia. It is the seventh-largest country.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Get English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Get punctuation marks\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "# Initialize list to store cleaned text\n",
    "cleaned_text = []\n",
    "\n",
    "# Filter out punctuation tokens and stop words\n",
    "for word in tokens:\n",
    "    if word not in punct:\n",
    "        if word.lower() not in stop_words:\n",
    "            cleaned_text.append(word)\n",
    "\n",
    "print('Original length:', len(text))\n",
    "print('Length of cleaned text:', len(cleaned_text))\n",
    "print('\\nCleaned text:', cleaned_text)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16fce2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india (hindi:bharat), officially the republic of india, is a country in south asia. it is the seventh-largest country.\n"
     ]
    }
   ],
   "source": [
    "# convert lower case \n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec1acecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDIA (HINDI:BHARAT), OFFICIALLY THE REPUBLIC OF INDIA, IS A COUNTRY IN SOUTH ASIA. IT IS THE SEVENTH-LARGEST COUNTRY.\n"
     ]
    }
   ],
   "source": [
    "# convert upper case\n",
    "print(text.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6a1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
