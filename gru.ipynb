{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\bhimr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data Collection \n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "# save to a file \n",
    "with open('hamlet.txt','w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4818"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## load dataset \n",
    "with open('hamlet.txt','r')as file:\n",
    "    text=file.read().lower()\n",
    "\n",
    "## tokenize the text\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create input sequences \n",
    "input_sequences=[]\n",
    "for line in text.split('\\n'):\n",
    "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_sequence=token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pad Sequences \n",
    "max_sequence_len=max([len(x) for x in input_sequences])\n",
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences=np.array(pad_sequences(input_sequences,maxlen=max_sequence_len,padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictors and label \n",
    "import tensorflow as tf\n",
    "x,y=input_sequences[:,:-1],input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert this into categorial \n",
    "y = tf.keras.utils.to_categorical(y,num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\LSTM RNN\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">481,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">113,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4818</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">727,518</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m481,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m113,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4818\u001b[0m)           │       \u001b[38;5;34m727,518\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,322,718</span> (5.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,322,718\u001b[0m (5.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,322,718</span> (5.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,322,718\u001b[0m (5.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dropout, Dense\n",
    "\n",
    "# Define the model with GRU\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1))\n",
    "model.add(GRU(150, return_sequences=False))  # GRU instead of LSTM, return_sequences=False for feeding into Dense\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "# Model compiler\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Build the model by explicitly defining the input shape (None for batch size)\n",
    "model.build(input_shape=(None, max_sequence_len))  # None for batch size, max_sequence_len for sequence length\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- GRU Layer: I replaced the LSTM layer with a GRU layer. Both are recurrent layers, but GRU uses a simplified gating mechanism compared to LSTM, making it less computationally expensive.\n",
    "- Same Structure: The rest of the model remains the same (Embedding, Dropout, Dense layers) because only the recurrent layer type was changed.\n",
    "Build Method: The input shape is defined using model.build(input_shape=(None, max_sequence_len)).\n",
    "- The GRU model will likely have similar performance to the LSTM but may train faster due to fewer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 33ms/step - accuracy: 0.0327 - loss: 7.1298 - val_accuracy: 0.0488 - val_loss: 6.6385\n",
      "Epoch 2/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.0515 - loss: 6.3086 - val_accuracy: 0.0589 - val_loss: 6.5844\n",
      "Epoch 3/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.0723 - loss: 5.9822 - val_accuracy: 0.0701 - val_loss: 6.6461\n",
      "Epoch 4/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.0841 - loss: 5.6293 - val_accuracy: 0.0781 - val_loss: 6.7456\n",
      "Epoch 5/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.1070 - loss: 5.2564 - val_accuracy: 0.0746 - val_loss: 6.8492\n",
      "Epoch 6/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.1228 - loss: 4.9113 - val_accuracy: 0.0754 - val_loss: 7.0383\n",
      "Epoch 7/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.1529 - loss: 4.5448 - val_accuracy: 0.0769 - val_loss: 7.2230\n",
      "Epoch 8/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.1987 - loss: 4.1701 - val_accuracy: 0.0760 - val_loss: 7.3471\n",
      "Epoch 9/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.2422 - loss: 3.8562 - val_accuracy: 0.0746 - val_loss: 7.4868\n",
      "Epoch 10/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.2914 - loss: 3.5431 - val_accuracy: 0.0764 - val_loss: 7.6612\n",
      "Epoch 11/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.3492 - loss: 3.2169 - val_accuracy: 0.0725 - val_loss: 7.7876\n",
      "Epoch 12/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.3915 - loss: 2.9706 - val_accuracy: 0.0678 - val_loss: 7.9342\n",
      "Epoch 13/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.4351 - loss: 2.7469 - val_accuracy: 0.0711 - val_loss: 8.0627\n",
      "Epoch 14/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.4690 - loss: 2.5581 - val_accuracy: 0.0725 - val_loss: 8.1791\n",
      "Epoch 15/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - accuracy: 0.5048 - loss: 2.3889 - val_accuracy: 0.0711 - val_loss: 8.2630\n",
      "Epoch 16/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.5281 - loss: 2.2273 - val_accuracy: 0.0680 - val_loss: 8.3236\n",
      "Epoch 17/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.5594 - loss: 2.0953 - val_accuracy: 0.0719 - val_loss: 8.4792\n",
      "Epoch 18/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.5844 - loss: 1.9509 - val_accuracy: 0.0717 - val_loss: 8.5693\n",
      "Epoch 19/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.6103 - loss: 1.8215 - val_accuracy: 0.0692 - val_loss: 8.6526\n",
      "Epoch 20/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.6232 - loss: 1.7309 - val_accuracy: 0.0690 - val_loss: 8.7256\n",
      "Epoch 21/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.6442 - loss: 1.6483 - val_accuracy: 0.0697 - val_loss: 8.8172\n",
      "Epoch 22/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 55ms/step - accuracy: 0.6617 - loss: 1.5358 - val_accuracy: 0.0651 - val_loss: 8.8980\n",
      "Epoch 23/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.6747 - loss: 1.4757 - val_accuracy: 0.0666 - val_loss: 8.9499\n",
      "Epoch 24/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.6817 - loss: 1.4409 - val_accuracy: 0.0697 - val_loss: 9.0556\n",
      "Epoch 25/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.6971 - loss: 1.3695 - val_accuracy: 0.0670 - val_loss: 9.1492\n",
      "Epoch 26/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.7149 - loss: 1.3112 - val_accuracy: 0.0668 - val_loss: 9.1922\n",
      "Epoch 27/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.7141 - loss: 1.2790 - val_accuracy: 0.0663 - val_loss: 9.2411\n",
      "Epoch 28/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.7263 - loss: 1.2253 - val_accuracy: 0.0655 - val_loss: 9.3241\n",
      "Epoch 29/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.7304 - loss: 1.1844 - val_accuracy: 0.0659 - val_loss: 9.3734\n",
      "Epoch 30/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.7394 - loss: 1.1436 - val_accuracy: 0.0628 - val_loss: 9.4314\n",
      "Epoch 31/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.7511 - loss: 1.1069 - val_accuracy: 0.0631 - val_loss: 9.4975\n",
      "Epoch 32/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.7568 - loss: 1.0816 - val_accuracy: 0.0616 - val_loss: 9.5552\n",
      "Epoch 33/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.7636 - loss: 1.0380 - val_accuracy: 0.0624 - val_loss: 9.6149\n",
      "Epoch 34/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 0.7648 - loss: 1.0228 - val_accuracy: 0.0618 - val_loss: 9.6337\n",
      "Epoch 35/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.7731 - loss: 0.9967 - val_accuracy: 0.0622 - val_loss: 9.7051\n",
      "Epoch 36/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.7715 - loss: 0.9969 - val_accuracy: 0.0659 - val_loss: 9.7591\n",
      "Epoch 37/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.7799 - loss: 0.9640 - val_accuracy: 0.0655 - val_loss: 9.7959\n",
      "Epoch 38/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.7751 - loss: 0.9767 - val_accuracy: 0.0664 - val_loss: 9.8499\n",
      "Epoch 39/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 50ms/step - accuracy: 0.7869 - loss: 0.9199 - val_accuracy: 0.0641 - val_loss: 9.8923\n",
      "Epoch 40/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 46ms/step - accuracy: 0.7891 - loss: 0.9251 - val_accuracy: 0.0645 - val_loss: 9.9331\n",
      "Epoch 41/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.7934 - loss: 0.9049 - val_accuracy: 0.0643 - val_loss: 9.9534\n",
      "Epoch 42/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.7972 - loss: 0.8993 - val_accuracy: 0.0633 - val_loss: 10.0243\n",
      "Epoch 43/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.7947 - loss: 0.8797 - val_accuracy: 0.0598 - val_loss: 10.0153\n",
      "Epoch 44/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.7926 - loss: 0.8800 - val_accuracy: 0.0628 - val_loss: 10.0927\n",
      "Epoch 45/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 41ms/step - accuracy: 0.7971 - loss: 0.8617 - val_accuracy: 0.0622 - val_loss: 10.1345\n",
      "Epoch 46/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.7980 - loss: 0.8570 - val_accuracy: 0.0620 - val_loss: 10.1424\n",
      "Epoch 47/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.8024 - loss: 0.8468 - val_accuracy: 0.0629 - val_loss: 10.1878\n",
      "Epoch 48/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.8044 - loss: 0.8460 - val_accuracy: 0.0602 - val_loss: 10.2063\n",
      "Epoch 49/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.8036 - loss: 0.8252 - val_accuracy: 0.0589 - val_loss: 10.2628\n",
      "Epoch 50/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.8073 - loss: 0.8282 - val_accuracy: 0.0583 - val_loss: 10.3100\n",
      "Epoch 51/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.8078 - loss: 0.8227 - val_accuracy: 0.0600 - val_loss: 10.3184\n",
      "Epoch 52/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.8144 - loss: 0.7865 - val_accuracy: 0.0596 - val_loss: 10.3584\n",
      "Epoch 53/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.8081 - loss: 0.8151 - val_accuracy: 0.0612 - val_loss: 10.3832\n",
      "Epoch 54/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.8068 - loss: 0.8080 - val_accuracy: 0.0608 - val_loss: 10.3791\n",
      "Epoch 55/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.8068 - loss: 0.8215 - val_accuracy: 0.0577 - val_loss: 10.4427\n",
      "Epoch 56/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.8086 - loss: 0.8093 - val_accuracy: 0.0618 - val_loss: 10.4477\n",
      "Epoch 57/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.8128 - loss: 0.7903 - val_accuracy: 0.0577 - val_loss: 10.4548\n",
      "Epoch 58/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 44ms/step - accuracy: 0.8132 - loss: 0.7698 - val_accuracy: 0.0567 - val_loss: 10.5158\n",
      "Epoch 59/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 45ms/step - accuracy: 0.8131 - loss: 0.7802 - val_accuracy: 0.0569 - val_loss: 10.4940\n",
      "Epoch 60/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 46ms/step - accuracy: 0.8209 - loss: 0.7487 - val_accuracy: 0.0583 - val_loss: 10.5177\n",
      "Epoch 61/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 46ms/step - accuracy: 0.8194 - loss: 0.7602 - val_accuracy: 0.0560 - val_loss: 10.5315\n",
      "Epoch 62/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 49ms/step - accuracy: 0.8225 - loss: 0.7466 - val_accuracy: 0.0618 - val_loss: 10.5842\n",
      "Epoch 63/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.8178 - loss: 0.7746 - val_accuracy: 0.0585 - val_loss: 10.5586\n",
      "Epoch 64/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 0.8163 - loss: 0.7607 - val_accuracy: 0.0558 - val_loss: 10.6111\n",
      "Epoch 65/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.8216 - loss: 0.7528 - val_accuracy: 0.0573 - val_loss: 10.6204\n",
      "Epoch 66/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 45ms/step - accuracy: 0.8228 - loss: 0.7437 - val_accuracy: 0.0556 - val_loss: 10.6349\n",
      "Epoch 67/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.8172 - loss: 0.7661 - val_accuracy: 0.0573 - val_loss: 10.6470\n",
      "Epoch 68/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.8199 - loss: 0.7556 - val_accuracy: 0.0563 - val_loss: 10.6527\n",
      "Epoch 69/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 44ms/step - accuracy: 0.8203 - loss: 0.7531 - val_accuracy: 0.0571 - val_loss: 10.6722\n",
      "Epoch 70/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8242 - loss: 0.7376 - val_accuracy: 0.0565 - val_loss: 10.7173\n",
      "Epoch 71/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.8232 - loss: 0.7329 - val_accuracy: 0.0571 - val_loss: 10.6861\n",
      "Epoch 72/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.8260 - loss: 0.7331 - val_accuracy: 0.0561 - val_loss: 10.7021\n",
      "Epoch 73/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8205 - loss: 0.7456 - val_accuracy: 0.0540 - val_loss: 10.7395\n",
      "Epoch 74/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.8248 - loss: 0.7328 - val_accuracy: 0.0602 - val_loss: 10.7200\n",
      "Epoch 75/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.8186 - loss: 0.7568 - val_accuracy: 0.0591 - val_loss: 10.7055\n",
      "Epoch 76/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.8244 - loss: 0.7337 - val_accuracy: 0.0550 - val_loss: 10.7379\n",
      "Epoch 77/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8244 - loss: 0.7329 - val_accuracy: 0.0565 - val_loss: 10.7618\n",
      "Epoch 78/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8258 - loss: 0.7246 - val_accuracy: 0.0567 - val_loss: 10.7621\n",
      "Epoch 79/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8223 - loss: 0.7333 - val_accuracy: 0.0595 - val_loss: 10.7869\n",
      "Epoch 80/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8256 - loss: 0.7131 - val_accuracy: 0.0577 - val_loss: 10.7779\n",
      "Epoch 81/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8249 - loss: 0.7053 - val_accuracy: 0.0563 - val_loss: 10.8102\n",
      "Epoch 82/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8245 - loss: 0.7105 - val_accuracy: 0.0579 - val_loss: 10.8434\n",
      "Epoch 83/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.8228 - loss: 0.7211 - val_accuracy: 0.0577 - val_loss: 10.8103\n",
      "Epoch 84/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 44ms/step - accuracy: 0.8237 - loss: 0.7268 - val_accuracy: 0.0589 - val_loss: 10.8975\n",
      "Epoch 85/85\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 46ms/step - accuracy: 0.8304 - loss: 0.7031 - val_accuracy: 0.0589 - val_loss: 10.8675\n"
     ]
    }
   ],
   "source": [
    "## Train the model \n",
    "history = model.fit(x_train,y_train,epochs=85,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the next word \n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Function to predict the next word\n",
    "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
    "    # Convert the input text into a sequence of tokens\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    \n",
    "    # Truncate the token list to the maximum sequence length\n",
    "    if len(token_list) >= max_sequence_len:\n",
    "        token_list = token_list[-(max_sequence_len-1):]\n",
    "    \n",
    "    # Pad the sequence to match the input shape expected by the model\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    \n",
    "    # Predict the next word\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)[0]\n",
    "    \n",
    "    # Find the word corresponding to the predicted index\n",
    "    predicted_word = {index: word for word, index in tokenizer.word_index.items()}.get(predicted_word_index)\n",
    "    \n",
    "    return predicted_word if predicted_word else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:To be or not to be\n",
      "Next Word Prediction : your\n"
     ]
    }
   ],
   "source": [
    "input_text = \"To be or not to be\"\n",
    "print(f\"Input text:{input_text}\")\n",
    "max_sequence_len=model.input_shape[1]+1\n",
    "next_word=predict_next_word(model,tokenizer,input_text,max_sequence_len)\n",
    "print(f\"Next Word Prediction : {next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:What is the best \n",
      "Next Word Prediction : marke\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is the best \"\n",
    "print(f\"Input text:{input_text}\")\n",
    "max_sequence_len=model.input_shape[1]+1\n",
    "next_word=predict_next_word(model,tokenizer,input_text,max_sequence_len)\n",
    "print(f\"Next Word Prediction : {next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with the new .keras extension\n",
    "model.save(\"next_word_gru.keras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
